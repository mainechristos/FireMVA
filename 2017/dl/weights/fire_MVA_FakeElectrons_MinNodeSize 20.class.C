// Class: ReadMinNodeSize 20
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : BDT::MinNodeSize 20
TMVA Release   : 4.2.1         [262657]
ROOT Release   : 6.14/07       [396807]
Creator        : mchristos
Date           : Thu Nov 15 23:19:58 2018
Host           : Linux cmsbuild02.cern.ch 2.6.32-754.3.5.el6.x86_64 #1 SMP Wed Aug 15 08:57:36 CEST 2018 x86_64 x86_64 x86_64 GNU/Linux
Dir            : /cms/mchristos/ANN/FireMVA/2017
Training events: 70707
Analysis type  : [Classification]


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
V: "False" [Verbose output (short form of "VerbosityLevel" below - overrides the latter one)]
H: "False" [Print method-specific help message]
NTrees: "50" [Number of trees in the forest]
MaxDepth: "6" [Max depth of the decision tree allowed]
MinNodeSize: "20.0%" [Minimum percentage of training events required in a leaf node (default: Classification: 5%, Regression: 0.2%)]
nCuts: "20" [Number of grid points in variable range used in finding optimal cut in node splitting]
BoostType: "Grad" [Boosting type for the trees in the forest (note: AdaCost is still experimental)]
Shrinkage: "1.000000e+00" [Learning rate for GradBoost algorithm]
# Default:
VerbosityLevel: "Default" [Verbosity level]
VarTransform: "None" [List of variable transformations performed before training, e.g., "D_Background,P_Signal,G,N_AllClasses" for: "Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)"]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
IgnoreNegWeightsInTraining: "False" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]
AdaBoostR2Loss: "quadratic" [Type of Loss function in AdaBoostR2]
UseBaggedBoost: "False" [Use only a random subsample of all events for growing the trees in each boost iteration.]
AdaBoostBeta: "5.000000e-01" [Learning rate  for AdaBoost algorithm]
UseRandomisedTrees: "False" [Determine at each node splitting the cut variable only as the best out of a random subset of variables (like in RandomForests)]
UseNvars: "5" [Size of the subset of variables used with RandomisedTree option]
UsePoissonNvars: "True" [Interpret "UseNvars" not as fixed number but as mean of a Poisson distribution in each split with RandomisedTree option]
BaggedSampleFraction: "6.000000e-01" [Relative size of bagged event sample to original size of the data sample (used whenever bagging is used (i.e. UseBaggedBoost, Bagging,)]
UseYesNoLeaf: "True" [Use Sig or Bkg categories, or the purity=S/(S+B) as classification of the leaf node -> Real-AdaBoost]
NegWeightTreatment: "pray" [How to treat events with negative weights in the BDT training (particular the boosting) : IgnoreInTraining;  Boost With inverse boostweight; Pair events with negative and positive weights in training sample and *annihilate* them (experimental!)]
Css: "1.000000e+00" [AdaCost: cost of true signal selected signal]
Cts_sb: "1.000000e+00" [AdaCost: cost of true signal selected bkg]
Ctb_ss: "1.000000e+00" [AdaCost: cost of true bkg    selected signal]
Cbb: "1.000000e+00" [AdaCost: cost of true bkg    selected bkg ]
NodePurityLimit: "5.000000e-01" [In boosting/pruning, nodes with purity > NodePurityLimit are signal; background otherwise.]
SeparationType: "giniindex" [Separation criterion for node splitting]
RegressionLossFunctionBDTG: "huber" [Loss function for BDTG regression.]
HuberQuantile: "7.000000e-01" [In the Huber loss function this is the quantile that separates the core from the tails in the residuals distribution.]
DoBoostMonitor: "False" [Create control plot with ROC integral vs tree number]
UseFisherCuts: "False" [Use multivariate splits using the Fisher criterion]
MinLinCorrForFisher: "8.000000e-01" [The minimum linear correlation between two variables demanded for use in Fisher criterion in node splitting]
UseExclusiveVars: "False" [Variables already used in fisher criterion are not anymore analysed individually for node splitting]
DoPreselection: "False" [and and apply automatic pre-selection for 100% efficient signal (bkg) cuts prior to training]
SigToBkgFraction: "1.000000e+00" [Sig to Bkg ratio used in Training (similar to NodePurityLimit, which cannot be used in real adaboost]
PruneMethod: "nopruning" [Note: for BDTs use small trees (e.g.MaxDepth=3) and NoPruning:  Pruning: Method used for pruning (removal) of statistically insignificant branches ]
PruneStrength: "0.000000e+00" [Pruning strength]
PruningValFraction: "5.000000e-01" [Fraction of events to use for optimizing automatic pruning.]
SkipNormalization: "False" [Skip normalization at initialization, to keep expectation value of BDT output according to the fraction of events]
nEventsMin: "0" [deprecated: Use MinNodeSize (in % of training events) instead]
UseBaggedGrad: "False" [deprecated: Use *UseBaggedBoost* instead:  Use only a random subsample of all events for growing the trees in each iteration.]
GradBaggingFraction: "6.000000e-01" [deprecated: Use *BaggedSampleFraction* instead: Defines the fraction of events to be used in each iteration, e.g. when UseBaggedGrad=kTRUE. ]
UseNTrainEvents: "0" [deprecated: Use *BaggedSampleFraction* instead: Number of randomly picked training events used in randomised (and bagged) trees]
NNodesMax: "0" [deprecated: Use MaxDepth instead to limit the tree size]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 27
abs(ElectronEta)              abs_ElectronEta_              abs(ElectronEta)              abs(ElectronEta)                                                'F'    [1.69258073583e-05,2.49997067451]
ElectronDXY                   ElectronDXY                   ElectronDXY                   ElectronDXY                                                     'F'    [6.64379129489e-08,0.0999782606959]
ElectronDZ                    ElectronDZ                    ElectronDZ                    ElectronDZ                                                      'F'    [4.06895367178e-07,0.199958592653]
ElectronSIP3D                 ElectronSIP3D                 ElectronSIP3D                 ElectronSIP3D                                                   'F'    [0.00396113377064,82.4355926514]
ElectronPtRatio               ElectronPtRatio               ElectronPtRatio               ElectronPtRatio                                                 'F'    [-1,3.24139928818]
ElectronPtRel                 ElectronPtRel                 ElectronPtRel                 ElectronPtRel                                                   'F'    [-1,970.202941895]
ElectronJetLRM                ElectronJetLRM                ElectronJetLRM                ElectronJetLRM                                                  'F'    [-1,0.33393111825]
ElectronJetFD                 ElectronJetFD                 ElectronJetFD                 ElectronJetFD                                                   'F'    [-1,1]
ElectronJetInOutRatio         ElectronJetInOutRatio         ElectronJetInOutRatio         ElectronJetInOutRatio                                           'F'    [-9999,1]
ElectronJetZest               ElectronJetZest               ElectronJetZest               ElectronJetZest                                                 'F'    [-1,1]
ElectronJetNoOfConst          ElectronJetNoOfConst          ElectronJetNoOfConst          ElectronJetNoOfConst                                            'F'    [0,73]
ElectronJetCSV                ElectronJetCSV                ElectronJetCSV                ElectronJetCSV                                                  'F'    [0,0.999627411366]
ElectronRelPFIsoPUCorr        ElectronRelPFIsoPUCorr        ElectronRelPFIsoPUCorr        ElectronRelPFIsoPUCorr                                          'F'    [0,1.76498115063]
ElectronRelTrkIso             ElectronRelTrkIso             ElectronRelTrkIso             ElectronRelTrkIso                                               'F'    [0,61.5004081726]
ElectronPFChargedHadronIso    ElectronPFChargedHadronIso    ElectronPFChargedHadronIso    ElectronPFChargedHadronIso                                      'F'    [0,92.4835739136]
ElectronPFNeutralHadronIso    ElectronPFNeutralHadronIso    ElectronPFNeutralHadronIso    ElectronPFNeutralHadronIso                                      'F'    [0,36.2971611023]
ElectronPFPhotonIso           ElectronPFPhotonIso           ElectronPFPhotonIso           ElectronPFPhotonIso                                             'F'    [0,77.488067627]
ElectronJetMuonEnergyFraction ElectronJetMuonEnergyFraction ElectronJetMuonEnergyFraction ElectronJetMuonEnergyFraction                                   'F'    [0,1]
ElectronJetElectronEnergyFraction ElectronJetElectronEnergyFraction ElectronJetElectronEnergyFraction ElectronJetElectronEnergyFraction                                       'F'    [0,1]
ElectronMissingHits           ElectronMissingHits           ElectronMissingHits           ElectronMissingHits                                             'F'    [0,1]
ElectronPassConversionVeto    ElectronPassConversionVeto    ElectronPassConversionVeto    ElectronPassConversionVeto                                      'F'    [1,1]
ElectronEInverseMinusPInverse ElectronEInverseMinusPInverse ElectronEInverseMinusPInverse ElectronEInverseMinusPInverse                                   'F'    [1.45857645961e-08,0.192345529795]
ElectronHoE                   ElectronHoE                   ElectronHoE                   ElectronHoE                                                     'F'    [0,1.74987196922]
ElectronDeltaPhiTrkSC         ElectronDeltaPhiTrkSC         ElectronDeltaPhiTrkSC         ElectronDeltaPhiTrkSC                                           'F'    [-0.168498814106,0.168645858765]
ElectronDeltaEtaTrkSeedSC     ElectronDeltaEtaTrkSeedSC     ElectronDeltaEtaTrkSeedSC     ElectronDeltaEtaTrkSeedSC                                       'F'    [-0.00673997402191,0.00673961639404]
ElectronFull5x5SigmaIEtaIEta  ElectronFull5x5SigmaIEtaIEta  ElectronFull5x5SigmaIEtaIEta  ElectronFull5x5SigmaIEtaIEta                                    'F'    [0,0.0424999594688]
ElectronPt                    ElectronPt                    ElectronPt                    ElectronPt                                                      'F'    [10.0002174377,1108.92687988]
NSpec 0


============================================================================ */

#include <array>
#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#define NN new MinNodeSize 20Node
   
#ifndef MinNodeSize 20Node__def
#define MinNodeSize 20Node__def
   
class MinNodeSize 20Node {
   
public:
   
   // constructor of an essentially "empty" node floating in space
   MinNodeSize 20Node ( MinNodeSize 20Node* left,MinNodeSize 20Node* right,
                          int selector, double cutValue, bool cutType, 
                          int nodeType, double purity, double response ) :
   fLeft         ( left         ),
   fRight        ( right        ),
   fSelector     ( selector     ),
   fCutValue     ( cutValue     ),
   fCutType      ( cutType      ),
   fNodeType     ( nodeType     ),
   fPurity       ( purity       ),
   fResponse     ( response     ){
   }

   virtual ~MinNodeSize 20Node();

   // test event if it descends the tree at this node to the right
   virtual bool GoesRight( const std::vector<double>& inputValues ) const;
   MinNodeSize 20Node* GetRight( void )  {return fRight; };

   // test event if it descends the tree at this node to the left 
   virtual bool GoesLeft ( const std::vector<double>& inputValues ) const;
   MinNodeSize 20Node* GetLeft( void ) { return fLeft; };   

   // return  S/(S+B) (purity) at this node (from  training)

   double GetPurity( void ) const { return fPurity; } 
   // return the node type
   int    GetNodeType( void ) const { return fNodeType; }
   double GetResponse(void) const {return fResponse;}

private:

   MinNodeSize 20Node*   fLeft;     // pointer to the left daughter node
   MinNodeSize 20Node*   fRight;    // pointer to the right daughter node
   int                     fSelector; // index of variable used in node selection (decision tree)   
   double                  fCutValue; // cut value applied on this node to discriminate bkg against sig
   bool                    fCutType;  // true: if event variable > cutValue ==> signal , false otherwise
   int                     fNodeType; // Type of node: -1 == Bkg-leaf, 1 == Signal-leaf, 0 = internal 
   double                  fPurity;   // Purity of node from training
   double                  fResponse; // Regression response value of node
}; 
   
//_______________________________________________________________________
   MinNodeSize 20Node::~MinNodeSize 20Node()
{
   if (fLeft  != NULL) delete fLeft;
   if (fRight != NULL) delete fRight;
}; 
   
//_______________________________________________________________________
bool MinNodeSize 20Node::GoesRight( const std::vector<double>& inputValues ) const
{
   // test event if it descends the tree at this node to the right
   bool result;
     result = (inputValues[fSelector] > fCutValue );
   if (fCutType == true) return result; //the cuts are selecting Signal ;
   else return !result;
}
   
//_______________________________________________________________________
bool MinNodeSize 20Node::GoesLeft( const std::vector<double>& inputValues ) const
{
   // test event if it descends the tree at this node to the left
   if (!this->GoesRight(inputValues)) return true;
   else return false;
}
   
#endif
   
#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() : fStatusIsClean( true ) {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;

   // returns classifier status
   bool IsStatusClean() const { return fStatusIsClean; }

 protected:

   bool fStatusIsClean;
};

#endif

class ReadMinNodeSize 20 : public IClassifierReader {

 public:

   // constructor
   ReadMinNodeSize 20( std::vector<std::string>& theInputVars )
      : IClassifierReader(),
        fClassName( "ReadMinNodeSize 20" ),
        fNvars( 27 ),
        fIsNormalised( false )
   {
      // the training input variables
      const char* inputVars[] = { "abs(ElectronEta)", "ElectronDXY", "ElectronDZ", "ElectronSIP3D", "ElectronPtRatio", "ElectronPtRel", "ElectronJetLRM", "ElectronJetFD", "ElectronJetInOutRatio", "ElectronJetZest", "ElectronJetNoOfConst", "ElectronJetCSV", "ElectronRelPFIsoPUCorr", "ElectronRelTrkIso", "ElectronPFChargedHadronIso", "ElectronPFNeutralHadronIso", "ElectronPFPhotonIso", "ElectronJetMuonEnergyFraction", "ElectronJetElectronEnergyFraction", "ElectronMissingHits", "ElectronPassConversionVeto", "ElectronEInverseMinusPInverse", "ElectronHoE", "ElectronDeltaPhiTrkSC", "ElectronDeltaEtaTrkSeedSC", "ElectronFull5x5SigmaIEtaIEta", "ElectronPt" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 0;
      fVmin[1] = 0;
      fVmax[1] = 0;
      fVmin[2] = 0;
      fVmax[2] = 0;
      fVmin[3] = 0;
      fVmax[3] = 0;
      fVmin[4] = 0;
      fVmax[4] = 0;
      fVmin[5] = 0;
      fVmax[5] = 0;
      fVmin[6] = 0;
      fVmax[6] = 0;
      fVmin[7] = 0;
      fVmax[7] = 0;
      fVmin[8] = 0;
      fVmax[8] = 0;
      fVmin[9] = 0;
      fVmax[9] = 0;
      fVmin[10] = 0;
      fVmax[10] = 0;
      fVmin[11] = 0;
      fVmax[11] = 0;
      fVmin[12] = 0;
      fVmax[12] = 0;
      fVmin[13] = 0;
      fVmax[13] = 0;
      fVmin[14] = 0;
      fVmax[14] = 0;
      fVmin[15] = 0;
      fVmax[15] = 0;
      fVmin[16] = 0;
      fVmax[16] = 0;
      fVmin[17] = 0;
      fVmax[17] = 0;
      fVmin[18] = 0;
      fVmax[18] = 0;
      fVmin[19] = 0;
      fVmax[19] = 0;
      fVmin[20] = 0;
      fVmax[20] = 0;
      fVmin[21] = 0;
      fVmax[21] = 0;
      fVmin[22] = 0;
      fVmax[22] = 0;
      fVmin[23] = 0;
      fVmax[23] = 0;
      fVmin[24] = 0;
      fVmax[24] = 0;
      fVmin[25] = 0;
      fVmax[25] = 0;
      fVmin[26] = 0;
      fVmax[26] = 0;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'F';
      fType[10] = 'F';
      fType[11] = 'F';
      fType[12] = 'F';
      fType[13] = 'F';
      fType[14] = 'F';
      fType[15] = 'F';
      fType[16] = 'F';
      fType[17] = 'F';
      fType[18] = 'F';
      fType[19] = 'F';
      fType[20] = 'F';
      fType[21] = 'F';
      fType[22] = 'F';
      fType[23] = 'F';
      fType[24] = 'F';
      fType[25] = 'F';
      fType[26] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadMinNodeSize 20() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const override;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[27];
   double fVmax[27];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[27];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)
   std::vector<MinNodeSize 20Node*> fForest;       // i.e. root nodes of decision trees
   std::vector<double>                fBoostWeights; // the weights applied in the individual boosts
};

double ReadMinNodeSize 20::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   double myMVA = 0;
   for (unsigned int itree=0; itree<fForest.size(); itree++){
      MinNodeSize 20Node *current = fForest[itree];
      while (current->GetNodeType() == 0) { //intermediate node
         if (current->GoesRight(inputValues)) current=(MinNodeSize 20Node*)current->GetRight();
         else current=(MinNodeSize 20Node*)current->GetLeft();
      }
      myMVA += current->GetResponse();
   }
   return 2.0/(1.0+exp(-2.0*myMVA))-1.0;
};

void ReadMinNodeSize 20::Initialize()
{
  // itree = 0
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.147473,-0.705055) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.376342,-0.247316) , 
18, 0.142857, 1, 0, 0.275057,-0.224943) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.641457,0.282915) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.80698,0.61396) , 
11, 0.908966, 1, 0, 0.73519,0.23519) , 
11, 0.618817, 1, 0, 0.5,-4.0518e-16)    );
  // itree = 1
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.596987,0.0697517) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.688033,0.273755) , 
10, 17.381, 1, 0, 0.64196,0.0691584) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.454817,-0.0578645) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.292186,-0.276493) , 
21, 0.00915932, 1, 0, 0.386005,-0.0585469) , 
25, 0.010119, 1, 0, 0.5,-0.00167065)    );
  // itree = 2
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.204893,-0.212366) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.442132,-0.0850405) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.621773,0.0449295) , 
18, 0.47619, 1, 0, 0.531938,-0.00589404) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.692572,0.193347) , 
16, 3.68991, 1, 0, 0.598499,0.026492) , 
11, 0.190405, 1, 0, 0.5,-0.000142735)    );
  // itree = 3
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.580891,0.0883739) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.431135,-0.0759255) , 
21, 0.00261663, 1, 0, 0.508138,0.00337313) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.284071,-0.131298) , 
21, 0.00915932, 1, 0, 0.42159,-0.0145404) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.755416,0.132318) , 
3, 7.85459, 1, 0, 0.5,-0.000606916)    );
  // itree = 4
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.215795,0.00983713) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.361613,0.142322) , 
11, 0.235717, 1, 0, 0.275057,0.0231436) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.686343,-0.120867) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.791299,-0.00253749) , 
10, 17.8571, 1, 0, 0.73519,-0.0239477) , 
11, 0.618817, 1, 0, 0.5,0.00012227)    );
  // itree = 5
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.405082,-0.07314) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.273395,-0.0486241) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.667332,0.106396) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.665322,0.0332243) , 
6, 0.113282, 1, 0, 0.666327,0.0250815) , 
18, 0.0464226, 1, 0, 0.54486,0.0129544) , 
10, 13.9048, 1, 0, 0.5,0.000143658)    );
  // itree = 6
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.480715,0.000337945) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.315871,-0.0758042) , 
0, 0.952394, 1, 0, 0.380118,-0.0152374) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.759494,-0.00494409) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.528074,0.0959572) , 
25, 0.0101181, 1, 0, 0.639388,0.0179573) , 
1, 0.00476093, 1, 0, 0.5,0.000111272)    );
  // itree = 7
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.276981,0.0167178) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.696366,-0.0771174) , 
11, 0.618799, 1, 0, 0.475609,-0.0100613) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.554813,0.0710106) , 
14, 8.80796, 1, 0, 0.5,-9.44436e-05)    );
  // itree = 8
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.281438,-0.0711235) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.371821,0.00706512) , 
9, 0.333333, 1, 0, 0.323399,-0.0111225) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.779043,0.0558987) , 
11, 0.809222, 1, 0, 0.5,0.000277198)    );
  // itree = 9
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.392242,-0.0577819) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.559864,0.0176261) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.653073,0.0917516) , 
18, 0.52381, 1, 0, 0.599729,0.0175527) , 
24, -0.00157435, 1, 0, 0.535139,0.00616584) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.386431,-0.0601703) , 
24, 0.00160453, 1, 0, 0.5,2.73637e-05)    );
  // itree = 10
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.596987,0.00604107) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.688033,-0.120006) , 
10, 17.381, 1, 0, 0.64196,-0.0155784) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.383222,0.098557) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.388837,-0.0132894) , 
7, 0.52381, 1, 0, 0.386005,0.0126262) , 
25, 0.010119, 1, 0, 0.5,6.46924e-05)    );
  // itree = 11
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.437799,-0.02065) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.483689,0.0262101) , 
14, 3.05382, 1, 0, 0.461433,0.000943781) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.476993,-0.0606168) , 
12, 0.50428, 1, 0, 0.466618,-0.00591679) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.594339,0.056465) , 
10, 20.8571, 1, 0, 0.5,0.000155029)    );
  // itree = 12
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.492894,0.0571128) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.200181,0.0323386) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.439499,-0.0274338) , 
11, 0.258407, 1, 0, 0.330732,-0.00188898) , 
0, 0.833335, 1, 0, 0.37991,0.00520518) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.805554,-0.047047) , 
11, 0.904425, 1, 0, 0.5,3.85942e-05)    );
  // itree = 13
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.27049,-0.0744249) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.485301,0.0392481) , 
3, 1.4993, 1, 0, 0.357435,-0.00840876) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.793537,0.0452345) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.611955,0.0285649) , 
0, 1.07143, 1, 0, 0.702684,0.0121078) , 
3, 3.92928, 1, 0, 0.5,6.32369e-05)    );
  // itree = 14
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.268943,0.021234) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.721208,-0.049303) , 
11, 0.618817, 1, 0, 0.489744,-0.004645) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.528422,0.0377132) , 
15, 1.72844, 1, 0, 0.5,-0.000115738)    );
  // itree = 15
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.157358,0.0652216) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.335051,-0.075405) , 
18, 0.380952, 1, 0, 0.245883,-0.00826492) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.691949,0.081324) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.682707,-0.0222862) , 
6, 0.0954421, 1, 0, 0.686293,0.00623154) , 
11, 0.428412, 1, 0, 0.5,9.95488e-05)    );
  // itree = 16
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.204893,0.0418663) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.440073,0.0543666) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.609159,-0.0174144) , 
1, 0.00476097, 1, 0, 0.531938,0.00547876) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.692572,-0.0556174) , 
16, 3.68991, 1, 0, 0.598499,-0.00411657) , 
11, 0.190405, 1, 0, 0.5,-8.95954e-05)    );
  // itree = 17
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.382487,0.00259517) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.204275,-0.0580728) , 
21, 0.00915932, 1, 0, 0.305552,-0.00681458) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.783676,0.0509578) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.748095,0.00784972) , 
6, 0.108718, 1, 0, 0.765766,0.00935645) , 
11, 0.761621, 1, 0, 0.5,1.79476e-05)    );
  // itree = 18
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.462489,-0.0327157) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.321934,-0.00317861) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.672118,0.0552609) , 
18, 0.342753, 1, 0, 0.527128,0.0108646) , 
8, 0.619048, 1, 0, 0.505799,0.00365928) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.483885,-0.0288629) , 
7, 0.619048, 1, 0, 0.5,-3.12989e-05)    );
  // itree = 19
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.288227,0.0478905) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.265146,-0.00368548) , 
14, 4.40398, 1, 0, 0.275057,0.00625245) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.734941,0.00402833) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.735528,-0.0517336) , 
2, 0.019039, 1, 0, 0.73519,-0.00640201) , 
11, 0.618817, 1, 0, 0.5,6.61208e-05)    );
  // itree = 20
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.216817,-0.0452567) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.570301,0.0175407) , 
11, 0.38075, 1, 0, 0.357435,-0.00585791) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.793537,0.0307184) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.611955,0.0202719) , 
0, 1.07143, 1, 0, 0.702684,0.00837033) , 
3, 3.92928, 1, 0, 0.5,1.7407e-05)    );
  // itree = 21
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.204893,0.0472908) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.548132,-0.0446655) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.624271,-0.0128887) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.644568,0.0389569) , 
6, 0.104837, 1, 0, 0.63375,0.00402837) , 
14, 4.40398, 1, 0, 0.598499,-0.00452719) , 
11, 0.190405, 1, 0, 0.5,-5.97675e-05)    );
  // itree = 22
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.564392,-0.00130573) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.367943,0.0471901) , 
25, 0.0182143, 1, 0, 0.470823,0.00753145) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.417303,-0.0891987) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.646041,0.0693341) , 
5, 1.85465, 1, 0, 0.52188,-0.00569835) , 
12, 0.336187, 1, 0, 0.5,-2.87584e-05)    );
  // itree = 23
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.540795,-0.00714945) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.328044,0.0693829) , 
21, 0.00915969, 1, 0, 0.454432,0.00664345) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.429439,-0.0295851) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.662366,-0.00831374) , 
1, 0.00474315, 1, 0, 0.545534,-0.00664657) , 
9, 0.333333, 1, 0, 0.5,-4.01559e-06)    );
  // itree = 24
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.582697,-0.0320668) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.454749,0.00762403) , 
0, 0.833109, 1, 0, 0.506353,-0.00279331) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.65033,0.0541291) , 
16, 5.3918, 1, 0, 0.547569,0.00278573) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.315844,-0.0344857) , 
25, 0.0303571, 1, 0, 0.5,-7.20446e-05)    );
  // itree = 25
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.389818,-0.0130172) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.491373,0.0338478) , 
10, 12.1429, 1, 0, 0.446286,0.00445105) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.68807,-0.0486987) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.44923,0.00939372) , 
25, 0.0101158, 1, 0, 0.573976,-0.00605411) , 
10, 17.381, 1, 0, 0.5,3.1981e-05)    );
  // itree = 26
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.627941,0.0325322) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.151571,0.0638749) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.354798,-0.0228615) , 
18, 0.142857, 1, 0, 0.259576,0.00182598) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.711963,-0.0228223) , 
11, 0.618817, 1, 0, 0.467393,-0.0026457) , 
0, 0.476199, 1, 0, 0.5,4.04333e-05)    );
  // itree = 27
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.243627,-0.0542921) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.345247,0.00480961) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.667875,0.0691384) , 
11, 0.473746, 1, 0, 0.493991,0.013944) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.814644,-0.0274133) , 
11, 0.904425, 1, 0, 0.607234,0.00636584) , 
18, 0.047619, 1, 0, 0.5,-0.000102608)    );
  // itree = 28
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.311894,-0.0448365) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.253618,0.0443227) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.496848,-0.0324441) , 
11, 0.326409, 1, 0, 0.367229,0.00154716) , 
6, 0.079849, 1, 0, 0.348653,-0.00395642) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.792707,0.0252147) , 
11, 0.856824, 1, 0, 0.5,3.36116e-05)    );
  // itree = 29
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.375337,0.0269043) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.476017,-0.0124942) , 
9, 0.333333, 1, 0, 0.420776,0.0027535) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.580019,-0.0332569) , 
16, 3.68991, 1, 0, 0.488758,-0.0028211) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.54426,0.0290662) , 
18, 0.619048, 1, 0, 0.5,-6.12403e-05)    );
  // itree = 30
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.473501,0.0223218) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.455126,0.0127661) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.465028,-0.0477601) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.617085,0.0150019) , 
26, 19.7145, 1, 0, 0.540683,-0.00649607) , 
6, 0.0795161, 1, 0, 0.510037,-0.00271301) , 
4, 0.4138, 1, 0, 0.5,7.51659e-06)    );
  // itree = 31
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.432918,-0.017933) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.622772,0.0284116) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.44129,-0.0110231) , 
24, 0.00087098, 1, 0, 0.531788,0.00283861) , 
24, -0.000963007, 1, 0, 0.5,1.02445e-06)    );
  // itree = 32
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.405082,0.0176814) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.522109,-0.0279662) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.57265,0.0119293) , 
6, 0.11428, 1, 0, 0.54486,-0.00287366) , 
10, 13.9048, 1, 0, 0.5,1.17591e-05)    );
  // itree = 33
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.673998,0.027138) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.501436,-0.0507211) , 
25, 0.00941912, 1, 0, 0.593035,-0.00299957) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.264169,0.0449847) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.47407,-0.01161) , 
18, 0.333333, 1, 0, 0.366615,0.00430179) , 
25, 0.0141667, 1, 0, 0.5,5.3087e-07)    );
  // itree = 34
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.330752,-0.0224401) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.591671,0.0359969) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.392914,0.0073563) , 
25, 0.0101181, 1, 0, 0.494349,0.00876742) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.814909,-0.0194842) , 
11, 0.904425, 1, 0, 0.603,0.00398125) , 
18, 0.380952, 1, 0, 0.5,-1.746e-05)    );
  // itree = 35
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.494324,-0.0353338) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.790341,-0.00622961) , 
3, 3.79909, 1, 0, 0.64196,-0.00746506) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.454817,-0.0206644) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.292186,0.0838367) , 
21, 0.00915932, 1, 0, 0.386005,0.0060144) , 
25, 0.010119, 1, 0, 0.5,1.10348e-05)    );
  // itree = 36
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.523281,0.0692729) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.824817,-0.00114753) , 
11, 0.856824, 1, 0, 0.666087,0.0141969) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.398159,-0.0348059) , 
25, 0.0242835, 1, 0, 0.583807,0.00595199) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.342526,-0.0365103) , 
21, 0.00915932, 1, 0, 0.5,-0.000151409)    );
  // itree = 37
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.236038,-0.0470484) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.556704,-0.0153737) , 
11, 0.244806, 1, 0, 0.399748,-0.0105476) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.262784,0.0136512) , 
0, 1.66665, 1, 0, 0.348653,-0.00495808) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.792707,0.0305986) , 
11, 0.856824, 1, 0, 0.5,-3.36546e-05)    );
  // itree = 38
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.147281,0.0603781) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.374769,-0.00219137) , 
18, 0.0952381, 1, 0, 0.275057,0.00540542) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.669816,-0.0350296) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.816354,0.011633) , 
11, 0.94523, 1, 0, 0.73519,-0.00567622) , 
11, 0.618817, 1, 0, 0.5,-1.20079e-05)    );
  // itree = 39
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.330752,-0.0199156) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.554794,-0.00274349) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.682916,0.0327121) , 
5, 2.4648, 1, 0, 0.603,0.00347783) , 
18, 0.380952, 1, 0, 0.5,-8.77845e-05)    );
  // itree = 40
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.207126,-0.0158712) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.63363,0.0325763) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.65074,0.00531412) , 
6, 0.11497, 1, 0, 0.641282,0.00681994) , 
11, 0.285599, 1, 0, 0.487618,0.00275075) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.532079,-0.0202992) , 
9, 0.428571, 1, 0, 0.5,9.29432e-06)    );
  // itree = 41
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.216327,0.0209381) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.533774,0.00460662) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.691003,-0.0175878) , 
1, 0.00476097, 1, 0, 0.624961,-0.00271546) , 
11, 0.238007, 1, 0, 0.5,9.80135e-06)    );
  // itree = 42
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.486543,-0.000988806) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.826704,-0.0307424) , 
11, 0.856824, 1, 0, 0.64196,-0.00385558) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.383222,-0.00895704) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.388837,0.0266685) , 
7, 0.52381, 1, 0, 0.386005,0.00308454) , 
25, 0.010119, 1, 0, 0.5,-6.38944e-06)    );
  // itree = 43
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.275615,-0.0271227) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.353694,0.00961463) , 
10, 17.381, 1, 0, 0.305552,-0.00434722) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.746352,0.0279364) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.785722,0.00796039) , 
1, 0.00948024, 1, 0, 0.765766,0.00598549) , 
11, 0.761621, 1, 0, 0.5,1.85202e-05)    );
  // itree = 44
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.339949,-0.0235992) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.433283,-0.00597493) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.527648,0.0158543) , 
9, 0.333333, 1, 0, 0.479737,0.00172359) , 
1, 0.00181371, 1, 0, 0.422483,-0.00207154) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.688188,0.0149428) , 
1, 0.0095218, 1, 0, 0.5,-6.76101e-06)    );
  // itree = 45
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.236767,0.000308887) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.328132,0.0240438) , 
16, 3.08367, 1, 0, 0.275057,0.00359088) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.735583,0.000648959) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.734658,-0.0277662) , 
9, 0.378522, 1, 0, 0.73519,-0.00376451) , 
11, 0.618817, 1, 0, 0.5,-4.91529e-06)    );
  // itree = 46
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.222182,0.0249812) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.583435,0.0255631) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.589652,-0.0218321) , 
4, 0.479853, 1, 0, 0.586909,-0.000381164) , 
11, 0.237999, 1, 0, 0.475609,0.00202511) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.554813,-0.0154149) , 
14, 8.80796, 1, 0, 0.5,9.6886e-06)    );
  // itree = 47
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.224608,-0.0174794) , 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.74367,0.0216729) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.492636,-0.00895058) , 
0, 1.42858, 1, 0, 0.644639,0.00284412) , 
11, 0.285608, 1, 0, 0.5,-2.57818e-06)    );
  // itree = 48
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.459585,0.0108224) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.346833,-0.00918216) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.622706,-0.0389112) , 
1, 0.00476096, 1, 0, 0.473774,-0.0077139) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.624505,0.0415994) , 
26, 26.0577, 1, 0, 0.519157,-0.00183103) , 
12, 0.25214, 1, 0, 0.5,8.82428e-06)    );
  // itree = 49
  fBoostWeights.push_back(1);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.473501,0.0167969) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, -99, 0.43405,-0.0192941) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.507419,0.027669) , 
6, 0.0898421, 1, 0, 0.469823,0.00168803) , 
NN(
0, 
0, 
-1, 0, 1, -99, 0.599663,-0.033526) , 
10, 18.1429, 1, 0, 0.510037,-0.00199827) , 
4, 0.4138, 1, 0, 0.5,3.6232e-05)    );
   return;
};
 
// Clean up
inline void ReadMinNodeSize 20::Clear() 
{
   for (unsigned int itree=0; itree<fForest.size(); itree++) { 
      delete fForest[itree]; 
   }
}
   inline double ReadMinNodeSize 20::GetMvaValue( const std::vector<double>& inputValues ) const
   {
      // classifier response value
      double retval = 0;

      // classifier response, sanity check first
      if (!IsStatusClean()) {
         std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
         retval = 0;
      }
      else {
         if (IsNormalised()) {
            // normalise variables
            std::vector<double> iV;
            iV.reserve(inputValues.size());
            int ivar = 0;
            for (std::vector<double>::const_iterator varIt = inputValues.begin();
                 varIt != inputValues.end(); varIt++, ivar++) {
               iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
            }
            retval = GetMvaValue__( iV );
         }
         else {
            retval = GetMvaValue__( inputValues );
         }
      }

      return retval;
   }
